{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet5 A-Z mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(r'C:\\Users\\User\\Desktop\\Learn-Machine-Learning\\Intro_to_DLNN\\DL_A-Zmnist -VGG16\\Dataset\\handwritten_data_785.csv')\n",
    "data = data.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random 10% of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = np.random.permutation(np.arange(len(data)))\n",
    "split0 = data.shape[0] * 7//10\n",
    "idx = cut[:split0]\n",
    "data_suff = data[idx]\n",
    "del data\n",
    "print(len(data_suff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "X = data_suff[:,1:]\n",
    "Y = data_suff[:,0]\n",
    "nr_to_letter = {k:v.upper() for k,v in enumerate(list(string.ascii_lowercase))}\n",
    "X=X.reshape(len(X),28,28)\n",
    "X = X[:,:,:,None]\n",
    "print(X.shape)\n",
    "print(Y)\n",
    "print(nr_to_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "for j,i in enumerate(np.random.choice(len(X),n)):\n",
    "    plt.subplot(1,n,j+1)\n",
    "    plt.imshow(X[i],cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.image.resize(X,[32,32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split to 80% train and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.permutation(np.arange(len(X)))\n",
    "split = X.shape[0] * 8//10 # แบ่ง train 80 %\n",
    "train_idx = idx[:split]\n",
    "test_idx = idx[split:]\n",
    "Xtrain,Ytrain,Xtest,Ytest = [],[],[],[]\n",
    "for idx in train_idx:\n",
    "    Xtrain.append(X[idx]/255.)\n",
    "    Ytrain.append(Y[idx].astype(np.int))\n",
    "Xtrain = np.array(Xtrain)    \n",
    "for idx in test_idx:\n",
    "    Xtest.append(X[idx]/255.)\n",
    "    Ytest.append(Y[idx].astype(np.int))  \n",
    "Xtrain,Ytrain,Xtest,Ytest = np.array(Xtrain) ,np.array(Ytrain) ,np.array(Xtest) ,np.array(Ytest)      \n",
    "# Xtrain,Ytrain = X[train_idx]/255.,Y[train_idx].astype(np.int)\n",
    "# Xtest,Ytest = X[test_idx]/255.,Y[test_idx].astype(np.int)\n",
    "print(Xtrain.shape)\n",
    "print(Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "for j,i in enumerate(np.random.choice(len(Xtrain),n)):\n",
    "    plt.subplot(1,n,j+1)\n",
    "    plt.imshow(Xtrain[i],cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\",input_shape=(224,224,3)))\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(128,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(256,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Conv2D(512,(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPool2D())\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(4096,activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss=tf.keras.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Xtrain, Ytrain), (Xtest, Ytest) = tf.keras.datasets.mnist.load_data()\n",
    "Xtrain = Xtrain[:, :, :, None]/255.\n",
    "Xtest = Xtest[:, :, :, None]/255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "batches = 8\n",
    "datagen.fit(Xtrain)\n",
    "num_batch = len(Xtrain)/batches\n",
    "Progbar = tf.keras.utils.Progbar(num_batch)\n",
    "for epoch in range(50):\n",
    "    batch_count = 0\n",
    "    model.save(r\"C:\\Users\\User\\Desktop\\Super_AI\\DL_NN\\DL_VGG16\\model\")\n",
    "    for x,y in datagen.flow(Xtrain,Ytrain,batch_size=batches):\n",
    "        x = tf.image.resize(x,(224,224))\n",
    "        x = tf.image.grayscale_to_rgb(x)\n",
    "        history = model.fit(x,y,verbose=0)\n",
    "        batch_count += 1\n",
    "        Progbar.update(batch_count,values=[('loss',history.history['loss'][0])])\n",
    "    if batch_count >= num_batch:\n",
    "        print(epoch)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save model as .pd file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r\"C:\\Users\\User\\Desktop\\Super_AI\\DL_NN\\DL_A-Zmnist\\Model\")\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(r\"C:\\Users\\User\\Desktop\\Super_AI\\DL_NN\\DL_A-Zmnist\\Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = loaded_model.predict(Xtest)\n",
    "print('Performance ',np.sum(Z.argmax(axis=1)==Ytest)/len(Z))\n",
    "# history = model\n",
    "# plt.plot(history.history['loss'])\n",
    "# plt.xlabel('epoch')\n",
    "# plt.ylabel('loss')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "print('Predict : ',Z[n])\n",
    "print('Max : ',np.amax(Z[n]))\n",
    "print('Predict index :',np.where(Z[n] == np.amax(Z[n]))[0],\n",
    "        '| Predict Answer :',nr_to_letter.get(np.where(Z[n] == np.amax(Z[n]))[0][0]),\n",
    "        '| Xtest :',Ytest[n])\n",
    "plt.imshow(Xtest[n],cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer Learning VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 5s 0us/step\n",
      "58900480/58889256 [==============================] - 5s 0us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 3)         6         \n",
      "_________________________________________________________________\n",
      "vgg16 (Functional)           (None, None, None, 512)   14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 14,719,824\n",
      "Trainable params: 14,719,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "vgg = VGG16(include_top=False, weights='imagenet')\n",
    "# fit input\n",
    "x_in = layers.Input(shape=(32, 32, 1))\n",
    "x = layers.Conv2D(3, 1)(x_in)\n",
    "x = vgg(x)\n",
    "# fit output\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "model = Model(x_in, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = tf.image.resize(Xtrain, (32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 58s 30ms/step - loss: 0.1717\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0298\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0202\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 56s 30ms/step - loss: 0.0151\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0108\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 57s 30ms/step - loss: 0.0092\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0073\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 53s 28ms/step - loss: 0.0063\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0054\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d33e3aeb50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(Xtrain, Ytrain, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Xtest = tf.image.resize(Xtest, (32, 32))\n",
    "Ztest = model.predict(Xtest)\n",
    "np.sum(Ztest.argmax(axis=1) == Ytest)/len(Ztest)\n",
    "# 0.996"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import layers\n",
    "vgg = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "\n",
    "# fit output\n",
    "x = layers.Flatten()(vgg.output)\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "model = tf.keras.Model(vgg.input, x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = tf.image.grayscale_to_rgb(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(Xtrain, Ytrain, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = tf.image.grayscale_to_rgb(Xtest)\n",
    "Ztest = model.predict(Xtest)\n",
    "np.sum(Ztest.argmax(axis=1) == Ytest)/len(Ztest)\n",
    "# 0.9951"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
